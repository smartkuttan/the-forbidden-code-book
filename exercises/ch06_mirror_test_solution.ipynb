{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'M': 1.0, 'F': 0.6666666666666666}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Toy data\n",
        "D = pd.DataFrame({\n",
        "    \"applicant_id\": [1, 2, 3, 4, 5, 6],\n",
        "    \"gender\": [\"M\", \"F\", \"M\", \"F\", \"M\", \"F\"],\n",
        "    \"approved\": [1, 0, 1, 0, 1, 0],\n",
        "    \"prediction\": [1, 0, 1, 1, 1, 0],\n",
        "})\n",
        "\n",
        "def group_accuracy(df, group_col, outcome_col, pred_col):\n",
        "    res = {}\n",
        "    for g in df[group_col].unique():\n",
        "        subset = df[df[group_col] == g]\n",
        "        cm = confusion_matrix(subset[outcome_col], subset[pred_col], labels=[0, 1])\n",
        "        acc = (cm[0,0] + cm[1,1]) / cm.sum()\n",
        "        res[g] = acc\n",
        "    return res\n",
        "\n",
        "print(group_accuracy(D, \"gender\", \"approved\", \"prediction\"))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
